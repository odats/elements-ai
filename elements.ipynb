{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import uuid\n",
    "import math\n",
    "import random\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from shapely.geometry import LineString, Point, LinearRing, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Computer vision: arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_augmentation(img_src):\n",
    "    datagen = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "        rotation_range=90,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    img = load_img(img_src)  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 128, 128)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 128, 128)\n",
    "\n",
    "    # the .flow() command below generates batches of randomly transformed images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir='prediction/augmentation', save_prefix='aug_', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#test_augmentation(\"data/train/line/c693fbb6d5e0435e92c01d486b652cd9.jpg\")\n",
    "#test_augmentation(\"data/train/arrow/IMG_2472 copy.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # dimensions of our images.\n",
    "    img_width, img_height = 128, 128\n",
    "\n",
    "    train_data_dir = 'data/train'\n",
    "    validation_data_dir = 'data/validation'\n",
    "    nb_train_samples = 1000\n",
    "    nb_validation_samples = 400\n",
    "    epochs = 9\n",
    "    batch_size = 16\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # this is the augmentation configuration we will use for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=90,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    # this is the augmentation configuration we will use for testing:\n",
    "    # only rescaling\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=90)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "    #model.save_weights('first_try.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, img_src):\n",
    "    img_width, img_height = 128, 128\n",
    "    \n",
    "    img = image.load_img(img_src, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    # x = np.expand_dims(x, axis=0)\n",
    "    x = np.array([x])\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    preds1 = model.predict_proba(x)\n",
    "\n",
    "    print(preds)\n",
    "    print(preds1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def addHeatMap(image, box_list):\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, box_list)\n",
    "    \n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "    return draw_img\n",
    "    \n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sliding windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img1, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    img = np.copy(img1)\n",
    "    step = xy_window[0]\n",
    "    \n",
    "    # fix when there is no mach between count of windows and image shape \n",
    "    # window: (33,33) image(100,100)\n",
    "    if(xy_overlap[0] > 0):\n",
    "        width = img.shape[0]\n",
    "        length = img.shape[1]\n",
    "        \n",
    "        a = math.ceil(img.shape[0] / (xy_window[0]*xy_overlap[0])) * (xy_window[0]*xy_overlap[0])\n",
    "        b = math.ceil(img.shape[1] / (xy_window[1]*xy_overlap[1])) * (xy_window[1]*xy_overlap[1])\n",
    "        \n",
    "        img = cv2.resize(img1, (int(b), int(a)))\n",
    "    \n",
    "        step = int(math.ceil(xy_window[0] * xy_overlap[0]))\n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    for x in xrange(0,img.shape[0],step):\n",
    "        for y in xrange(0,img.shape[1],step):\n",
    "            #  window_list.append(((startx, starty), (endx, endy)))\n",
    "            window_list.append(((y, x), (y+xy_window[1],x+xy_window[0])))\n",
    "    \n",
    "    # Return the list of windows\n",
    "    return window_list, img # fixed resized window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window1(img1, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    img = np.copy(img1)\n",
    "    \n",
    "    # fix when there is no mach between count of windows and image shape \n",
    "    # window: (33,33) image(100,100)\n",
    "    if(xy_overlap[0] > 0):\n",
    "        width = img.shape[0]\n",
    "        length = img.shape[1]\n",
    "        \n",
    "        a = math.ceil(img.shape[0] / (xy_window[0]*xy_overlap[0])) * (xy_window[0]*xy_overlap[0])\n",
    "        b = math.ceil(img.shape[1] / (xy_window[1]*xy_overlap[1])) * (xy_window[1]*xy_overlap[1])\n",
    "        \n",
    "        img = cv2.resize(img1, (int(b), int(a)))\n",
    "    \n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list, img # fixed resized window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def slide_window_scale(img, scales, xy_window):\n",
    "    windows_all = []\n",
    "    for scale in scales:\n",
    "        resized_img = cv2.resize(img, (np.int(img.shape[1]/scale), np.int(img.shape[0]/scale)))\n",
    "        windows, resized_fixed_img = slide_window(resized_img, xy_window=xy_window)\n",
    "        for window in windows:\n",
    "            windows_all.append(window)            \n",
    "            cv2.rectangle(resized_fixed_img, (window[0][0], window[0][1]), (window[1][0], window[1][1]),(0,0,255),6)\n",
    "        plt.imshow(resized_fixed_img)\n",
    "        plt.show() \n",
    "        \n",
    "    return windows_all\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pipeline_vision(model, image_src, xy_window = (128, 128), scales = [2]):\n",
    "    img = mpimg.imread(image_src)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    windows = slide_window_scale(img, scales, xy_window)\n",
    "    print(len(windows))   \n",
    "\n",
    "    hot_windows = []\n",
    "    for window in windows:\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], xy_window)      \n",
    "\n",
    "        x = image.img_to_array(test_img)\n",
    "        x = np.array([x])\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "\n",
    "        # arrow\n",
    "        if(preds[0]==0):        \n",
    "            hot_windows.append(((window[0][0], window[0][1]), (window[1][0], window[1][1])))\n",
    "\n",
    "            #mpimg.imsave(\"prediction/\" + uuid.uuid4().hex + \".jpg\", test_img)\n",
    "            #plt.imshow(test_img)\n",
    "            #plt.show()\n",
    "\n",
    "    draw_img3 = addHeatMap(img, hot_windows)\n",
    "    plt.imshow(draw_img3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pipeline_vision_single(model, image_src, xy_window = (128, 128), scale = 2, generate_data=False):\n",
    "    img1 = mpimg.imread(image_src)\n",
    "    img2 = cv2.resize(img1, (np.int(img1.shape[1]/scale), np.int(img1.shape[0]/scale)))\n",
    "    windows, img3 = slide_window(img2, xy_window=xy_window)\n",
    "    \n",
    "    #print(img1.shape)\n",
    "    #print(img2.shape)\n",
    "    #print(img3.shape)\n",
    "    \n",
    "    draw_img1 = np.copy(img3) # all rectangles\n",
    "    draw_img2 = np.copy(img3) # arrow\n",
    "    draw_img3 = np.copy(img3) # use heat maps\n",
    "    \n",
    "    hot_windows = []\n",
    "    print(len(windows))\n",
    "    for window in windows:\n",
    "        #print(window)\n",
    "        cv2.rectangle(draw_img1, (window[0][0], window[0][1]), (window[1][0], window[1][1]),(0,0,255),6)\n",
    "        \n",
    "        test_img = cv2.resize(img3[window[0][1]:window[1][1], window[0][0]:window[1][0]], xy_window)\n",
    "        x = image.img_to_array(test_img)\n",
    "        x = np.array([x])\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "\n",
    "        # arrow\n",
    "        if(preds[0]==0):\n",
    "            cv2.rectangle(draw_img2, (window[0][0], window[0][1]), (window[1][0], window[1][1]),(0,0,255),6)\n",
    "            hot_windows.append(((window[0][0], window[0][1]), (window[1][0], window[1][1])))\n",
    "\n",
    "            #mpimg.imsave(\"prediction/temp/\" + uuid.uuid4().hex + \".jpg\", test_img)\n",
    "            #plt.imshow(test_img)\n",
    "            #plt.show()\n",
    "            \n",
    "    if(generate_data):\n",
    "        files = glob.glob('test_data/generate/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "        for window in windows:\n",
    "            test_img = cv2.resize(img3[window[0][1]:window[1][1], window[0][0]:window[1][0]], xy_window)\n",
    "            mpimg.imsave(\"test_data/generate/\" + uuid.uuid4().hex + \".jpg\", test_img)\n",
    "\n",
    "    draw_img3 = addHeatMap(img3, hot_windows)        \n",
    "\n",
    "    plt.imshow(draw_img1)\n",
    "    plt.show()    \n",
    "    plt.imshow(draw_img2)\n",
    "    plt.show()  \n",
    "    plt.imshow(draw_img3)\n",
    "    plt.show()\n",
    "    \n",
    "    mpimg.imsave(\"prediction/\" + \"result1\" + \".jpg\", draw_img2)\n",
    "    mpimg.imsave(\"prediction/\" + \"result2\" + \".jpg\", draw_img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in xrange(0, len(seq), size))\n",
    "\n",
    "def operation(sess, softmax_tensor, image, window, image_number):\n",
    "    # prepare data for prediction\n",
    "    test_img = cv2.resize(image[window[0][1]:window[1][1], window[0][0]:window[1][0]], dsize=(299,299), interpolation = cv2.INTER_CUBIC)\n",
    "    np_image_data = np.asarray(test_img)\n",
    "    np_image_data=cv2.normalize(np_image_data.astype('float'), None, -0.5, .5, cv2.NORM_MINMAX)\n",
    "    #maybe insert float convertion here - see edit remark!\n",
    "    image_data = np.expand_dims(np_image_data,axis=0)\n",
    "\n",
    "    # predict\n",
    "    predictions = sess.run(softmax_tensor, {'Mul:0': image_data})\n",
    "    \n",
    "    return predictions, image_number, window\n",
    "\n",
    "def pipeline_vision_single_tf_2(image_src, xy_window = (128, 128), scale = 2, generate_data=False):\n",
    "    # get windows    \n",
    "    # get predictions    \n",
    "    # merge hotwindow\n",
    "    \n",
    "    # load and prepare image\n",
    "    img1 = mpimg.imread(image_src)\n",
    "    # rescale\n",
    "    img2 = cv2.resize(img1, (np.int(img1.shape[1]/scale), np.int(img1.shape[0]/scale)))\n",
    "    # resize image to have nice sliding window\n",
    "    hot_windows = []\n",
    "    windows_full, img3 = slide_window(img2, xy_window=xy_window)\n",
    "    print(len(windows_full))\n",
    "    #print(img1.shape)\n",
    "    #print(img2.shape)\n",
    "    #print(img3.shape)\n",
    "    \n",
    "    draw_img1 = np.copy(img3) # all rectangles\n",
    "    draw_img2 = np.copy(img3) # arrow\n",
    "    draw_img3 = np.copy(img3) # use heat maps   \n",
    "    \n",
    "    #--------------------------------------------------------------------\n",
    "    # use TensorFlow to predict data\n",
    "    \n",
    "    # Unpersists graph from file\n",
    "    with tf.gfile.FastGFile(\"tf/retrained_graph.pb\", 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "    \n",
    "    # loads label file, strips off carriage return\n",
    "    label_lines = [line.rstrip() for line \n",
    "                       in tf.gfile.GFile(\"tf/retrained_labels.txt\")]\n",
    "    \n",
    "    pool = ThreadPool()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        \n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            for windows in chunker(windows_full, 100):\n",
    "                \n",
    "                threads = [pool.apply_async(operation, args=(sess, softmax_tensor, img3, windows[image_number], image_number)) for\n",
    "                       image_number in range(len(windows))]\n",
    "                result = []\n",
    "                for thread in threads:\n",
    "                    result.append(thread.get())\n",
    "                \n",
    "                for result in result:\n",
    "                    predictions = result[0]\n",
    "                    window = result[2]\n",
    "                    \n",
    "                    # Log: draw rectangle\n",
    "                    #cv2.rectangle(draw_img1, (window[0][0], window[0][1]), (window[1][0], window[1][1]),(0,0,255),6)        \n",
    "           \n",
    "                \n",
    "                    # Sort to show labels of first prediction in order of confidence\n",
    "                    top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]            \n",
    "                    for node_id in top_k:            \n",
    "                        human_string = label_lines[node_id]\n",
    "                        score = predictions[0][node_id]\n",
    "                        #print('%s (score = %.5f)' % (human_string, score))\n",
    "                        if(human_string==\"arrow\" and score > 0.5):\n",
    "                            # save window\n",
    "                            hot_windows.append(((window[0][0], window[0][1]), (window[1][0], window[1][1])))\n",
    "\n",
    "                            # Log: draw rectangle on top of prediction\n",
    "                            cv2.rectangle(draw_img2, (window[0][0], window[0][1]), (window[1][0], window[1][1]),(0,0,255),6)\n",
    "\n",
    "                            # Log: save predicted image\n",
    "                            #mpimg.imsave(\"prediction/temp/\" + uuid.uuid4().hex + \".jpg\", test_img)\n",
    "                            #plt.imshow(test_img)\n",
    "                            #plt.show()\n",
    "            \n",
    "    # merge window\n",
    "    draw_img3 = addHeatMap(img3, hot_windows)        \n",
    "\n",
    "    #--------------------------------------------------------------------\n",
    "    # Log:\n",
    "    plt.imshow(draw_img1)\n",
    "    plt.show()    \n",
    "    plt.imshow(draw_img2)\n",
    "    plt.show()  \n",
    "    plt.imshow(draw_img3)\n",
    "    plt.show()\n",
    "    \n",
    "    mpimg.imsave(\"prediction/\" + \"result1\" + \".jpg\", draw_img2)\n",
    "    mpimg.imsave(\"prediction/\" + \"result2\" + \".jpg\", draw_img3)\n",
    "    \n",
    "    # Log: generate test data\n",
    "    if(generate_data):\n",
    "        files = glob.glob('test_data/generate/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "        for window in windows:\n",
    "            test_img = cv2.resize(img3[window[0][1]:window[1][1], window[0][0]:window[1][0]], xy_window)\n",
    "            mpimg.imsave(\"test_data/generate/\" + uuid.uuid4().hex + \".jpg\", test_img)\n",
    "            \n",
    "     #--------------------------------------------------------------------\n",
    "    \n",
    "    return hot_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Process lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "# https://stackoverflow.com/questions/32702075/what-would-be-the-fastest-way-to-find-the-maximum-of-all-possible-distances-betw\n",
    "def lines_close(line1, line2):\n",
    "    dist1 = math.hypot(line1[0][0] - line2[0][0], line1[0][0] - line2[0][1])\n",
    "    dist2 = math.hypot(line1[0][2] - line2[0][0], line1[0][3] - line2[0][1])\n",
    "    dist3 = math.hypot(line1[0][0] - line2[0][2], line1[0][0] - line2[0][3])\n",
    "    dist4 = math.hypot(line1[0][2] - line2[0][2], line1[0][3] - line2[0][3])\n",
    "    \n",
    "    if (min(dist1,dist2,dist3,dist4) < 100):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def lineMagnitude (x1, y1, x2, y2):\n",
    "    lineMagnitude = math.sqrt(math.pow((x2 - x1), 2)+ math.pow((y2 - y1), 2))\n",
    "    return lineMagnitude\n",
    " \n",
    "#Calc minimum distance from a point and a line segment (i.e. consecutive vertices in a polyline).\n",
    "# https://nodedangles.wordpress.com/2010/05/16/measuring-distance-from-a-point-to-a-line-segment/\n",
    "# http://paulbourke.net/geometry/pointlineplane/\n",
    "def DistancePointLine(px, py, x1, y1, x2, y2):\n",
    "    #http://local.wasp.uwa.edu.au/~pbourke/geometry/pointline/source.vba\n",
    "    LineMag = lineMagnitude(x1, y1, x2, y2)\n",
    " \n",
    "    if LineMag < 0.00000001:\n",
    "        DistancePointLine = 9999\n",
    "        return DistancePointLine\n",
    " \n",
    "    u1 = (((px - x1) * (x2 - x1)) + ((py - y1) * (y2 - y1)))\n",
    "    u = u1 / (LineMag * LineMag)\n",
    " \n",
    "    if (u < 0.00001) or (u > 1):\n",
    "        #// closest point does not fall within the line segment, take the shorter distance\n",
    "        #// to an endpoint\n",
    "        ix = lineMagnitude(px, py, x1, y1)\n",
    "        iy = lineMagnitude(px, py, x2, y2)\n",
    "        if ix > iy:\n",
    "            DistancePointLine = iy\n",
    "        else:\n",
    "            DistancePointLine = ix\n",
    "    else:\n",
    "        # Intersecting point is on the line, use the formula\n",
    "        ix = x1 + u * (x2 - x1)\n",
    "        iy = y1 + u * (y2 - y1)\n",
    "        DistancePointLine = lineMagnitude(px, py, ix, iy)\n",
    " \n",
    "    return DistancePointLine\n",
    "\n",
    "def get_distance(line1, line2):\n",
    "    dist1 = DistancePointLine(line1[0][0], line1[0][1], \n",
    "                              line2[0][0], line2[0][1], line2[1][0], line2[1][1])\n",
    "    dist2 = DistancePointLine(line1[1][0], line1[1][1], \n",
    "                              line2[0][0], line2[0][1], line2[1][0], line2[1][1])\n",
    "    dist3 = DistancePointLine(line2[0][0], line2[0][1], \n",
    "                              line1[0][0], line1[0][1], line1[1][0], line1[1][1])\n",
    "    dist4 = DistancePointLine(line2[1][0], line2[1][1], \n",
    "                              line1[0][0], line1[0][1], line1[1][0], line1[1][1])\n",
    "    \n",
    "    \n",
    "    return min(dist1,dist2,dist3,dist4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_lines_segments1(lines, use_log=False):\n",
    "    if(len(lines) == 1):\n",
    "        return lines[0]\n",
    "    \n",
    "    line_i = lines[0]\n",
    "    \n",
    "    # orientation\n",
    "    orientation_i = math.atan2((line_i[0][1]-line_i[1][1]),(line_i[0][0]-line_i[1][0]))\n",
    "    \n",
    "    points = []\n",
    "    for line in lines:\n",
    "        points.append(line[0])\n",
    "        points.append(line[1])\n",
    "        \n",
    "    if (abs(math.degrees(orientation_i)) > 45) and abs(math.degrees(orientation_i)) < (90+45):\n",
    "        \n",
    "        #sort by y\n",
    "        points = sorted(points, key=lambda point: point[1])\n",
    "        \n",
    "        if use_log:\n",
    "            print(\"use y\")\n",
    "    else:\n",
    "        \n",
    "        #sort by x\n",
    "        points = sorted(points, key=lambda point: point[0])\n",
    "        \n",
    "        if use_log:\n",
    "            print(\"use x\")\n",
    "    \n",
    "    return [points[0], points[len(points)-1]]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_line_segments1(line_i, line_j, use_log=False): \n",
    "    # orientation\n",
    "    orientation_i = math.atan2((line_i[0][1]-line_i[1][1]),(line_i[0][0]-line_i[1][0]))\n",
    "    orientation_j = math.atan2((line_j[0][1]-line_j[1][1]),(line_j[0][0]-line_j[1][0]))\n",
    "        \n",
    "    if (abs(math.degrees(orientation_i)) > 45) and abs(math.degrees(orientation_i)) < (90+45):\n",
    "        start_y = max(line_i[0][1],line_i[1][1],line_j[0][1],line_j[1][1])\n",
    "        end_y = min(line_i[0][1],line_i[1][1],line_j[0][1],line_j[1][1])\n",
    "\n",
    "        avg_x = int(np.mean([line_i[0][0],line_i[1][0],line_j[0][0],line_j[1][0]]))\n",
    "        start_x = avg_x\n",
    "        end_x = avg_x\n",
    "        \n",
    "        if use_log:\n",
    "            print(\"use y\")\n",
    "    else:\n",
    "        start_x = min(line_i[0][0],line_i[1][0],line_j[0][0],line_j[1][0])\n",
    "        end_x = max(line_i[0][0],line_i[1][0],line_j[0][0],line_j[1][0])\n",
    "\n",
    "        avg_y = int(np.mean([line_i[0][1],line_i[1][1],line_j[0][1],line_j[1][1]]))\n",
    "        start_y = avg_y\n",
    "        end_y = avg_y\n",
    "        \n",
    "        if use_log:\n",
    "            print(\"use x\")\n",
    "    \n",
    "    if(use_log):\n",
    "        print(\"real lines angle:\", math.degrees(orientation_i), math.degrees(orientation_j)) \n",
    "        print(\"initial endpoints:\", line_i, line_j)\n",
    "        print(\"final line endpoints:\", (start_x, start_y), (end_x, end_y))\n",
    "        \n",
    "        # Create a black image\n",
    "        img = np.zeros((600,600,3), np.uint8)\n",
    "        img = cv2.line(img, line_i[0],line_i[1],(255,0,0),5)\n",
    "        img = cv2.line(img,line_j[0],line_j[1],(255,0,0),5)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "               \n",
    "        img = cv2.line(img, (start_x, start_y), (end_x, end_y),(255,0,255),5)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return [(start_x, start_y), (end_x, end_y)]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TAVARES and PADILHA approach\n",
    "def merge_line_segments(line_i, line_j, use_log=False):    \n",
    "    # line distance\n",
    "    line_i_length = math.hypot(line_i[1][0] - line_i[0][0], line_i[1][1] - line_i[0][1])\n",
    "    line_j_length = math.hypot(line_j[1][0] - line_j[0][0], line_j[1][1] - line_j[0][1])\n",
    "    \n",
    "    # centroids\n",
    "    Xg = line_i_length*(line_i[0][0]+line_i[1][0]) + line_j_length*(line_j[0][0]+line_j[1][0])\n",
    "    Xg /= 2 * (line_i_length + line_j_length)\n",
    "    \n",
    "    Yg = line_i_length*(line_i[0][1]+line_i[1][1]) + line_j_length*(line_j[0][1]+line_j[1][1])\n",
    "    Yg /= 2 * (line_i_length + line_j_length)\n",
    "    \n",
    "    # orientation\n",
    "    orientation_i = math.atan2((line_i[0][1]-line_i[1][1]),(line_i[0][0]-line_i[1][0]))\n",
    "    orientation_j = math.atan2((line_j[0][1]-line_j[1][1]),(line_j[0][0]-line_j[1][0]))    \n",
    "    orientation_r = math.pi\n",
    "    if(abs(orientation_i - orientation_j) <= math.pi/2):\n",
    "        orientation_r = line_i_length*orientation_i + line_j_length*orientation_j\n",
    "        orientation_r /= line_i_length + line_j_length\n",
    "    else:\n",
    "        orientation_r = line_i_length*orientation_i + line_j_length*(orientation_j - math.pi*orientation_j/abs(orientation_j))\n",
    "        orientation_r /= line_i_length + line_j_length\n",
    "    \n",
    "    # coordinate transformation\n",
    "    # δXG = (δy - yG)sinθr + (δx - xG)cosθr\n",
    "    # δYG = (δy - yG)cosθr - (δx - xG)sinθr\n",
    "    a_x_g = (line_i[0][1] - Yg)*math.sin(orientation_r) + (line_i[0][0] - Xg) * math.cos(orientation_r)\n",
    "    a_y_g = (line_i[0][1] - Yg)*math.cos(orientation_r) - (line_i[0][0] - Xg) * math.sin(orientation_r)\n",
    "    \n",
    "    b_x_g = (line_i[1][1] - Yg)*math.sin(orientation_r) + (line_i[1][0] - Xg) * math.cos(orientation_r)\n",
    "    b_y_g = (line_i[1][1] - Yg)*math.cos(orientation_r) - (line_i[1][0] - Xg) * math.sin(orientation_r)\n",
    "    \n",
    "    c_x_g = (line_j[0][1] - Yg)*math.sin(orientation_r) + (line_j[0][0] - Xg) * math.cos(orientation_r)\n",
    "    c_y_g = (line_j[0][1] - Yg)*math.cos(orientation_r) - (line_j[0][0] - Xg) * math.sin(orientation_r)\n",
    "    \n",
    "    d_x_g = (line_j[1][1] - Yg)*math.sin(orientation_r) + (line_j[1][0] - Xg) * math.cos(orientation_r)\n",
    "    d_y_g = (line_j[1][1] - Yg)*math.cos(orientation_r) - (line_j[1][0] - Xg) * math.sin(orientation_r)\n",
    "    \n",
    "    # line distance relative\n",
    "    line_i_rel_length = math.hypot(b_x_g - a_x_g, b_y_g - a_y_g)\n",
    "    line_j_rel_length = math.hypot(d_x_g - c_x_g, d_y_g - c_y_g)   \n",
    "    \n",
    "    # orthogonal projections over the axis X\n",
    "    start_f = min(a_x_g,b_x_g,c_x_g,d_x_g)\n",
    "    end_f = max(a_x_g,b_x_g,c_x_g,d_x_g)\n",
    "    length_f = math.hypot(end_f - start_f, 0 - 0)\n",
    "    \n",
    "    #start_f = line_i_rel_length * math.cos(orientation_r)\n",
    "    #end_f = line_j_rel_length * math.cos(orientation_r)\n",
    "    \n",
    "    start_x = int(Xg - start_f * math.cos(orientation_r))\n",
    "    start_y = int(Yg - start_f * math.sin(orientation_r))\n",
    "    end_x = int(Xg - end_f * math.cos(orientation_r))\n",
    "    end_y = int(Yg - end_f * math.sin(orientation_r))   \n",
    "    \n",
    "    # log process\n",
    "    if(use_log):    \n",
    "        print(\"distance between lines:\", get_distance(line_i, line_j))\n",
    "        print(\"real lines angle:\", math.degrees(orientation_i), math.degrees(orientation_j))\n",
    "        print(\"orientation angle:\", math.degrees(orientation_r))\n",
    "        print(\"centroids:\", Xg, Yg)      \n",
    "        print(\"relative lines length:\", line_i_rel_length, line_j_rel_length) \n",
    "        print(\"real lines length:\", line_i_length, line_j_length)\n",
    "        print(\"final line length\", length_f)\n",
    "        print(\"final line endpoints\", (start_x, start_y), (end_x, end_y))\n",
    "        \n",
    "        # Create a black image\n",
    "        img = np.zeros((1400,3100,3), np.uint8)\n",
    "        img = cv2.line(img, line_i[0],line_i[1],(255,0,0),5)\n",
    "        img = cv2.line(img,line_j[0],line_j[1],(255,0,0),5)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        img = cv2.circle(img,(int(Xg),int(Yg)),10,(255,0,100),6)        \n",
    "        img = cv2.line(img, (start_x, start_y), (end_x, end_y),(255,0,255),5)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return [(start_x, start_y), (end_x, end_y)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use y\n",
      "('real lines angle:', -90.0, -90.0)\n",
      "('initial endpoints:', [(100, 100), (100, 400)], [(200, 100), (200, 300)])\n",
      "('final line endpoints:', (150, 400), (150, 100))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsJDUxbCQ1OX/AcNcN3HpjpKVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49b6732450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49b66f2650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use x\n",
      "('real lines angle:', 180.0, 180.0)\n",
      "('initial endpoints:', [(100, 100), (400, 100)], [(200, 300), (350, 300)])\n",
      "('final line endpoints:', (100, 200), (400, 200))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49b6732410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0Mdw/j2O1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f49b42e8810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(100, 200), (400, 200)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_line_segments1([(100,100),(100,400)], [(200,100),(200,300)], True)\n",
    "merge_line_segments1([(100,100),(400,100)], [(200,300),(350,300)], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_lines_pipeline(lines):\n",
    "    super_lines = []\n",
    "    min_distance_to_merge = 30\n",
    "    min_angle_to_merge = 30\n",
    "    debug = False\n",
    "    \n",
    "    for line in lines:\n",
    "        create_super_line = True\n",
    "        for idx, super_line in enumerate(super_lines):\n",
    "            # check the distance between lines\n",
    "            if get_distance(super_line, line) < min_distance_to_merge:\n",
    "                # check the angle between lines       \n",
    "                orientation_i = math.atan2((line[0][1]-line[1][1]),(line[0][0]-line[1][0]))\n",
    "                orientation_j = math.atan2((super_line[0][1]-super_line[1][1]),(super_line[0][0]-super_line[1][0]))\n",
    "                \n",
    "                if int(abs(abs(math.degrees(orientation_i)) - abs(math.degrees(orientation_j)))) < min_angle_to_merge: \n",
    "                    #print(\"angles\", orientation_i, orientation_j)\n",
    "                    #print(int(abs(orientation_i - orientation_j)))\n",
    "                    new_line = merge_line_segments1(super_line, line, debug)\n",
    "                    super_lines[idx] = new_line\n",
    "                    create_super_line = False\n",
    "                    #break # go to next line\n",
    "        if (create_super_line):\n",
    "            # create new super line if we could not find close line and merge\n",
    "            super_lines.append(line)\n",
    "\n",
    "    return super_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def merge_lines_pipeline_2(lines):\n",
    "    super_lines_final = []\n",
    "    super_lines = []\n",
    "    min_distance_to_merge = 30\n",
    "    min_angle_to_merge = 30\n",
    "    \n",
    "    for line in lines:\n",
    "        create_new_group = True\n",
    "        group_updated = False\n",
    "\n",
    "        for group in super_lines:\n",
    "            for line2 in group:\n",
    "                if get_distance(line2, line) < min_distance_to_merge:\n",
    "                    # check the angle between lines       \n",
    "                    orientation_i = math.atan2((line[0][1]-line[1][1]),(line[0][0]-line[1][0]))\n",
    "                    orientation_j = math.atan2((line2[0][1]-line2[1][1]),(line2[0][0]-line2[1][0]))\n",
    "\n",
    "                    if int(abs(abs(math.degrees(orientation_i)) - abs(math.degrees(orientation_j)))) < min_angle_to_merge: \n",
    "                        #print(\"angles\", orientation_i, orientation_j)\n",
    "                        #print(int(abs(orientation_i - orientation_j)))\n",
    "                        group.append(line)\n",
    "\n",
    "                        create_new_group = False\n",
    "                        group_updated = True\n",
    "                        break\n",
    "            \n",
    "            if group_updated:\n",
    "                break\n",
    "\n",
    "        if (create_new_group):\n",
    "            new_group = []\n",
    "            new_group.append(line)\n",
    "\n",
    "            for idx, line2 in enumerate(lines):\n",
    "                # check the distance between lines\n",
    "                if get_distance(line2, line) < min_distance_to_merge:\n",
    "                    # check the angle between lines       \n",
    "                    orientation_i = math.atan2((line[0][1]-line[1][1]),(line[0][0]-line[1][0]))\n",
    "                    orientation_j = math.atan2((line2[0][1]-line2[1][1]),(line2[0][0]-line2[1][0]))\n",
    "\n",
    "                    if int(abs(abs(math.degrees(orientation_i)) - abs(math.degrees(orientation_j)))) < min_angle_to_merge: \n",
    "                        #print(\"angles\", orientation_i, orientation_j)\n",
    "                        #print(int(abs(orientation_i - orientation_j)))\n",
    "\n",
    "                        new_group.append(line2)\n",
    "\n",
    "                        # remove line from lines list\n",
    "                        #lines[idx] = False\n",
    "            # append new group\n",
    "            super_lines.append(new_group)\n",
    "        \n",
    "    \n",
    "    for group in super_lines:\n",
    "        super_lines_final.append(merge_lines_segments1(group))\n",
    "    \n",
    "    return super_lines_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
    "# http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html\n",
    "def get_lines(lines_in):\n",
    "    if cv2.__version__ < '3.0':\n",
    "        return lines_in[0]\n",
    "    return [l[0] for l in lines_in]\n",
    "\n",
    "def process_lines(image_src):\n",
    "    img = mpimg.imread(image_src)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, thresh1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    thresh1 = cv2.bitwise_not(thresh1)\n",
    "    \n",
    "    edges = cv2.Canny(thresh1, threshold1=50, threshold2=200, apertureSize = 3)\n",
    "\n",
    "    lines = cv2.HoughLinesP(thresh1, rho=1, theta=np.pi/180, threshold=50,\n",
    "                            minLineLength=50, maxLineGap=30)\n",
    "\n",
    "    # l[0] - line; l[1] - angle\n",
    "    for line in get_lines(lines):\n",
    "        leftx, boty, rightx, topy = line\n",
    "        cv2.line(img, (leftx, boty), (rightx,topy), (0,0,255), 6) \n",
    "        \n",
    "    # merge lines\n",
    "        \n",
    "    #------------------\n",
    "    # prepare\n",
    "    _lines = []\n",
    "    for _line in get_lines(lines):\n",
    "        _lines.append([(_line[0], _line[1]),(_line[2], _line[3])])\n",
    "        \n",
    "    # sort\n",
    "    _lines_x = []\n",
    "    _lines_y = []\n",
    "    for line_i in _lines:\n",
    "        orientation_i = math.atan2((line_i[0][1]-line_i[1][1]),(line_i[0][0]-line_i[1][0]))\n",
    "        if (abs(math.degrees(orientation_i)) > 45) and abs(math.degrees(orientation_i)) < (90+45):\n",
    "            _lines_y.append(line_i)\n",
    "        else:\n",
    "            _lines_x.append(line_i)\n",
    "            \n",
    "    _lines_x = sorted(_lines_x, key=lambda _line: _line[0][0])\n",
    "    _lines_y = sorted(_lines_y, key=lambda _line: _line[0][1])\n",
    "        \n",
    "    merged_lines_x = merge_lines_pipeline_2(_lines_x)\n",
    "    merged_lines_y = merge_lines_pipeline_2(_lines_y)\n",
    "    \n",
    "    merged_lines_all = []\n",
    "    merged_lines_all.extend(merged_lines_x)\n",
    "    merged_lines_all.extend(merged_lines_y)\n",
    "    print(\"process groups lines\", len(_lines), len(merged_lines_all))\n",
    "    img_merged_lines = mpimg.imread(image_src)\n",
    "    for line in merged_lines_all:\n",
    "        cv2.line(img_merged_lines, (line[0][0], line[0][1]), (line[1][0],line[1][1]), (0,0,255), 6)\n",
    "\n",
    "    \n",
    "    cv2.imwrite('prediction/lines_gray.jpg',gray)\n",
    "    cv2.imwrite('prediction/lines_thresh.jpg',thresh1)\n",
    "    cv2.imwrite('prediction/lines_edges.jpg',edges)\n",
    "    cv2.imwrite('prediction/lines_lines.jpg',img)\n",
    "    cv2.imwrite('prediction/merged_lines.jpg',img_merged_lines)\n",
    "    \n",
    "    return merged_lines_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://toblerity.org/shapely/manual.html#object.intersects\n",
    "\n",
    "https://gis.stackexchange.com/questions/182542/difference-between-crosses-intersects-shapely-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DataTable:\n",
    "    data = []\n",
    "    rectangles = []\n",
    "    rectangles_intersections = []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        self.rectangles = []\n",
    "        self.rectangles_intersections = []\n",
    "        \n",
    "    #-------------------------------------------------\n",
    "    # Query data\n",
    "        \n",
    "    def contains_record(self, item, line1, line2):\n",
    "        _line1 = item[0]['_id']\n",
    "        _line2 = item[1]['_id']\n",
    "        \n",
    "        if(_line1 == line1['_id'] and _line2 == line2['_id']):\n",
    "            return True\n",
    "        elif(_line1 == line2['_id'] and _line2 == line1['_id']):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def contains(self, line1, line2):\n",
    "        count = sum(1 for item in self.data if self.contains_record(item, line1, line2))\n",
    "        return count > 0\n",
    "    \n",
    "    def insert(self, line1, line2, intersaction):\n",
    "        if(line1['_id'] == line2['_id']):\n",
    "            # can not have connections with the same line \n",
    "            return False\n",
    "        \n",
    "        if not self.contains(line1, line2):\n",
    "            self.data.append([line1, line2, intersaction])\n",
    "        \n",
    "    def find_by_lines(self, filter_lines):\n",
    "        result = []\n",
    "        \n",
    "        for item in self.data:\n",
    "            for line in filter_lines:\n",
    "                if (item[0]['_id'] == line['_id'] or item[1]['_id'] == line['_id']):\n",
    "                    result.append(item)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def unique_lines(self, filtered_data, filter_lines):\n",
    "        result = []\n",
    "\n",
    "        for item in filtered_data:\n",
    "            unique = True\n",
    "            for line in filter_lines:                \n",
    "                if item[0]['_id'] == line['_id']:\n",
    "                    unique = False               \n",
    "                    \n",
    "            if(unique):\n",
    "                result.append(item[0])\n",
    "                \n",
    "        for item in filtered_data:\n",
    "            unique = True\n",
    "            for line in filter_lines:                \n",
    "                if item[1]['_id'] == line['_id']:\n",
    "                    unique = False               \n",
    "                    \n",
    "            if(unique):\n",
    "                result.append(item[1])\n",
    "                \n",
    "\n",
    "        return result\n",
    "    \n",
    "    def find_intersection(self, line1, line2):        \n",
    "        connections = [item for item in self.data if self.contains_record(item, line1, line2)]\n",
    "        if(len(connections) > 0):\n",
    "            return connections[0][2]\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    #-------------------------------------------------\n",
    "    # rectangles\n",
    "    \n",
    "    def insert_rectangle(self, start_line,line2,line3,line4):\n",
    "        self.rectangles.append([start_line,line2,line3,line4])\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def rectangles_exist(self, start_line,line2,line3,line4):\n",
    "        for rectangle in self.rectangles:\n",
    "            coincidence = 0\n",
    "            for line in rectangle:                \n",
    "                for _line in [start_line,line2,line3,line4]:\n",
    "                    if(line['_id'] == _line['_id']):\n",
    "                        coincidence +=1\n",
    "            if coincidence == 4:\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def get_linear_ring(self, rectangle):\n",
    "        points = []\n",
    "        for item in rectangle:\n",
    "            points.append([item.x,item.y])\n",
    "            \n",
    "        figure = Polygon(points)\n",
    "        \n",
    "        return figure\n",
    "    \n",
    "    def get_linear_ring_by_rect(self, rectangle):\n",
    "        points = []\n",
    "        for item in rectangle:\n",
    "            points.append(item['line'][0])\n",
    "            points.append(item['line'][1])\n",
    "            \n",
    "        figure = Polygon(points)\n",
    "        \n",
    "        return figure\n",
    "        \n",
    "    \n",
    "    def clear_rectangles(self):\n",
    "        clean_rectangles = []\n",
    "        clean_rectangles_intersections = []\n",
    "\n",
    "        for idx1, rectangle1 in enumerate(self.rectangles):\n",
    "            use_rectangle = True\n",
    "            ring1 = self.get_linear_ring(rectangle1)\n",
    "            #print(\"area\", ring1.area)\n",
    "            #print(rectangle1)\n",
    "            \n",
    "            for idx2, rectangle2 in enumerate(self.rectangles):\n",
    "                if(idx1 == idx2):\n",
    "                    continue\n",
    "                else:\n",
    "                    ring2 = self.get_linear_ring(rectangle2)\n",
    "                    if(ring1.intersects(ring2)):\n",
    "                        if(ring1.area > ring2.area):\n",
    "                            use_rectangle = True\n",
    "                        else:\n",
    "                            use_rectangle = False\n",
    "                            break\n",
    "            \n",
    "            if(use_rectangle):\n",
    "                clean_rectangles.append(rectangle1)\n",
    "                clean_rectangles_intersections.append(self.rectangles_intersections[idx1])                       \n",
    "                       \n",
    "        print(\"clear rectangles\", len(self.rectangles), len(clean_rectangles))\n",
    "        self.rectangles = clean_rectangles\n",
    "        self.rectangles_intersections = clean_rectangles_intersections\n",
    "        \n",
    "    def clear_rectangles_by_intersections(self):\n",
    "        clean_rectangles_intersections = []\n",
    "        clean_rectangles = []        \n",
    "\n",
    "        for idx1, rectangle1 in enumerate(self.rectangles_intersections):\n",
    "            use_rectangle = True\n",
    "            ring1 = self.get_linear_ring(rectangle1)\n",
    "            \n",
    "            for idx2, rectangle2 in enumerate(self.rectangles_intersections):\n",
    "                if(idx1 == idx2):\n",
    "                    continue\n",
    "                else:\n",
    "                    ring2 = self.get_linear_ring(rectangle2)\n",
    "                    # filter by intersaction or distance\n",
    "                    if(ring1.intersects(ring2) or ring1.distance(ring2) < 50):                        \n",
    "                        # check the difference\n",
    "                        print(ring1.area, ring2.area)\n",
    "                        if (abs(ring1.area - ring2.area) < 5000):\n",
    "                            print(\"small dif\")\n",
    "                            rect1 = self.get_linear_ring_by_rect(self.rectangles[idx1])\n",
    "                            rect2 = self.get_linear_ring_by_rect(self.rectangles[idx2])\n",
    "                            if(rect1.length > rect2.length):\n",
    "                                use_rectangle = False\n",
    "                                break\n",
    "                            \n",
    "                        elif (ring1.area < ring2.area):                            \n",
    "                            use_rectangle = False\n",
    "                            break\n",
    "                    \n",
    "                    # filter by area (skip very small rects)\n",
    "            \n",
    "            if(use_rectangle):\n",
    "                clean_rectangles_intersections.append(self.rectangles_intersections[idx1])                \n",
    "                clean_rectangles.append(self.rectangles[idx1])                       \n",
    "                       \n",
    "        print(\"clear rectangles\", len(self.rectangles), len(clean_rectangles))\n",
    "        \n",
    "        self.rectangles_intersections = clean_rectangles_intersections\n",
    "        self.rectangles = clean_rectangles\n",
    "        \n",
    "                                   \n",
    "    \n",
    "    # end rectangles\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    # Lines\n",
    "    \n",
    "    def get_connected_lines(self, start_line, group):\n",
    "        next_line = get_connected_lines(start_line)\n",
    "        if next_line:\n",
    "            group.append(next_line)\n",
    "            return get_connected_lines(self, next_line, group)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    def get_available_lines(self):\n",
    "        available_lines = []\n",
    "        available_connections = []\n",
    "        \n",
    "        for connection in self.data:\n",
    "            coincidence1 = 0\n",
    "            coincidence2 = 0\n",
    "            \n",
    "            # line is not in rectangles\n",
    "            for rectangle in self.rectangles:\n",
    "                for line in rectangle:\n",
    "                    if connection[0]['_id'] == line['_id']:\n",
    "                        coincidence1 += 1\n",
    "                    if connection[1]['_id'] == line['_id']:\n",
    "                        coincidence2 += 1\n",
    "                        \n",
    "            if coincidence1 == 0:\n",
    "                # check on duplications\n",
    "                count = sum(1 for item in available_lines if item['_id'] == connection[0][\"_id\"])\n",
    "                if count == 0:\n",
    "                    available_lines.append(connection[0])\n",
    "            if coincidence2 == 0:\n",
    "                # check on duplications\n",
    "                count = sum(1 for item in available_lines if item['_id'] == connection[1][\"_id\"])\n",
    "                if count == 0:\n",
    "                    available_lines.append(connection[1])\n",
    "                    \n",
    "            if coincidence1 == 0 and coincidence2 == 0:\n",
    "                available_connections.append(connection)\n",
    "            \n",
    "                        \n",
    "        return available_lines, available_connections\n",
    "    \n",
    "    def get_available_parent_lines(self, available_lines):\n",
    "        # if line has intersaction with rectangle\n",
    "        result = []\n",
    "        for line in available_lines:\n",
    "            coincidence = 0\n",
    "            connections = self.find_by_lines([line])\n",
    "            for connection in connections:\n",
    "                for rectangle in self.rectangles:\n",
    "                    for rect_line in rectangle:\n",
    "                        if rect_line['_id'] == connection[0]['_id'] or rect_line['_id'] == connection[1]['_id']:\n",
    "                            coincidence += 1\n",
    "                            break\n",
    "                    if coincidence > 0:\n",
    "                        break\n",
    "                if coincidence > 0:\n",
    "                    break\n",
    "            \n",
    "            if coincidence > 0:\n",
    "                count = sum(1 for item in result if line['_id'] == item['_id'])\n",
    "                if count == 0:\n",
    "                    result.append(line)\n",
    "        \n",
    "        return result\n",
    "                    \n",
    "    \n",
    "    def find_connections_recursively(self, parent_line, line, available_connections, group):\n",
    "        \n",
    "        count = sum(1 for item in group if line['_id'] == item['_id'])\n",
    "        if count > 1:\n",
    "            return\n",
    "        else:\n",
    "            group.append(line)\n",
    "        \n",
    "        next_line = False\n",
    "        for connection in available_connections:\n",
    "            if connection[0][\"_id\"] == line[\"_id\"] and connection[1][\"_id\"] != parent_line[\"_id\"]:\n",
    "                next_line = connection[1]\n",
    "                break\n",
    "            if connection[1][\"_id\"] == line[\"_id\"] and connection[0][\"_id\"] != parent_line[\"_id\"]:\n",
    "                next_line = connection[0]\n",
    "                break\n",
    "        \n",
    "        if next_line:\n",
    "            return self.find_connections_recursively(line, next_line, available_connections, group)\n",
    "        else:\n",
    "            return\n",
    "            \n",
    "        \n",
    "\n",
    "def geometry(_lines, arrows, image_src):\n",
    "    # assing id to lines\n",
    "    lines = []\n",
    "    for line in _lines:\n",
    "        lines.append({\n",
    "            '_id': uuid.uuid4().hex,\n",
    "            'line': line\n",
    "        })\n",
    "        \n",
    "    \n",
    "    # fill data table by intersacting lines\n",
    "    data_table = DataTable()\n",
    "    for line1 in lines:\n",
    "        for line2 in lines:\n",
    "            if(line1['_id'] == line2['_id']):\n",
    "                continue\n",
    "\n",
    "            if not data_table.contains(line1, line2):               \n",
    "                a = LineString(line1['line'])\n",
    "                b = LineString(line2['line'])\n",
    "                # check for intersaction\n",
    "                if(a.intersects(b)):\n",
    "                    intersaction = a.intersection(b)\n",
    "                    data_table.insert(line1, line2, intersaction)\n",
    "                \n",
    "                elif(a.distance(b) < 100):                \n",
    "                    # try to connect nearest lines\n",
    "                    p11 = Point(a.coords[0])\n",
    "                    p12 = Point(a.coords[1])\n",
    "                    p21 = Point(b.coords[0])\n",
    "                    p22 = Point(b.coords[1])\n",
    "                    points = []\n",
    "                    # could be improved by using point on the line rather then endpoints\n",
    "                    points.append([p21, a.distance(p21)])\n",
    "                    points.append([p22, a.distance(p22)])\n",
    "                    points.append([p11, b.distance(p11)])\n",
    "                    points.append([p12, b.distance(p12)])\n",
    "                    \n",
    "                    points = sorted(points, key=lambda point: point[1])\n",
    "                    data_table.insert(line1, line2, points[0][0])\n",
    "                    \n",
    "                \n",
    "    print(\"connections\", len(data_table.data))\n",
    "    \n",
    "    #---------------------------------------------------------------------\n",
    "    # find rectangles\n",
    "    for start_line in lines:\n",
    "        #print(1, start_line[\"_id\"])\n",
    "        connections1 = data_table.find_by_lines([start_line])        \n",
    "        # parce connection to get only second order lines\n",
    "        lines2 = data_table.unique_lines(connections1, [start_line])\n",
    "        #print(start_line[\"_id\"], len(connections1), len(lines2))\n",
    "        \n",
    "        for line2 in lines2:\n",
    "            #print(2, line2[\"_id\"])\n",
    "            connections2 = data_table.find_by_lines([line2])\n",
    "            lines3 = data_table.unique_lines(connections2, [start_line, line2])\n",
    "            \n",
    "            for line3 in lines3:\n",
    "                #print(3, line3[\"_id\"])\n",
    "                connections3 = data_table.find_by_lines([line3])\n",
    "                lines4 = data_table.unique_lines(connections3, [start_line, line2, line3])\n",
    "                \n",
    "                for line4 in lines4:\n",
    "                    #print(4, line4[\"_id\"])\n",
    "                    connections4 = data_table.find_by_lines([line4, start_line])\n",
    "                    \n",
    "                    if(len(connections4) > 0):\n",
    "                        if(not data_table.rectangles_exist(start_line,line2,line3,line4)):\n",
    "                        \n",
    "                            int1 = data_table.find_intersection(start_line, line2)\n",
    "                            int2 = data_table.find_intersection(line2, line3)\n",
    "                            int3 = data_table.find_intersection(line3, line4)\n",
    "                            int4 = data_table.find_intersection(line4, start_line)\n",
    "\n",
    "                            #print(int1, int2, int3, int3)\n",
    "                            if(int1 and int2 and int3 and int4):\n",
    "                                #print(\"created\")\n",
    "                                if(int1 != int4):\n",
    "                                    data_table.insert_rectangle(start_line,line2,line3,line4)                                \n",
    "                                    data_table.rectangles_intersections.append([int1, int2, int3, int4])\n",
    "                                \n",
    "    data_table.clear_rectangles_by_intersections()              \n",
    "    #---------------------------------------------------------------------\n",
    "    # lines\n",
    "    available_lines, available_connections = data_table.get_available_lines()\n",
    "    print(\"available_lines\", len(available_lines), len(available_connections))\n",
    "    # filter by: used in rectangles, have 2+ connections (only parent)\n",
    "    \n",
    "    available_lines_parents = data_table.get_available_parent_lines(available_lines)\n",
    "\n",
    "            \n",
    "    print(\"line parents\", len(available_lines_parents))\n",
    "                \n",
    "    \n",
    "    lines_groups = []\n",
    "    for new_line in available_lines_parents:\n",
    "        # check if line is already used in groups\n",
    "        coincidence = 0\n",
    "        for group in lines_groups:        \n",
    "            for existing_line in group:\n",
    "                if existing_line[\"_id\"] == new_line[\"_id\"]:\n",
    "                    coincidence += 1\n",
    "                    break\n",
    "            if coincidence > 0:\n",
    "                break\n",
    "        if coincidence == 0:\n",
    "            group = []\n",
    "            data_table.find_connections_recursively(new_line, new_line, available_connections, group)\n",
    "            lines_groups.append(group)\n",
    "    \n",
    "    # draw points on image\n",
    "    geometry_points = mpimg.imread(image_src)\n",
    "    for item in data_table.data:\n",
    "        intersection = item[2]\n",
    "        if(intersection.geom_type == \"Point\"):\n",
    "            cv2.circle(geometry_points, (int(intersection.x), int(intersection.y)), 8, (0, 255, 0), 8)\n",
    "    cv2.imwrite('prediction/geometry_points.jpg',geometry_points)\n",
    "        \n",
    "    # draw rectangles on image\n",
    "    geometry_rectangles = mpimg.imread(image_src)\n",
    "    for item in data_table.rectangles_intersections:\n",
    "        if(item[0].geom_type == \"Point\" and item[1].geom_type == \"Point\" and\n",
    "          item[2].geom_type == \"Point\" and item[3].geom_type == \"Point\"):\n",
    "            cv2.rectangle(geometry_rectangles, (int(item[0].x), int(item[0].y)), (int(item[2].x), int(item[2].y)),(0,0,255),6)\n",
    "    cv2.imwrite('prediction/geometry_rectangles.jpg',geometry_rectangles)\n",
    "    \n",
    "    # draw lines on image\n",
    "    geometry_lines = mpimg.imread(image_src)\n",
    "    for group in lines_groups:\n",
    "        color = (random.randint(0, 255),random.randint(0, 255),random.randint(0, 255))\n",
    "        for item in group:            \n",
    "            line = item['line']\n",
    "            cv2.line(geometry_lines, (line[0][0], line[0][1]), (line[1][0], line[1][1]),color,6)\n",
    "        \n",
    "    cv2.imwrite('prediction/geometry_lines.jpg',geometry_lines)\n",
    "    \n",
    "    \n",
    "    return data_table.rectangles_intersections, lines_groups\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#test_model(model, \"test_data/a2.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_to_test = \"test_data/to_test/andrew1.jpeg\"\n",
    "#img_to_test = \"test_data/examples/ross2.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:16:14\n",
      "16:16:14\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%X'))\n",
    "#pipeline_vision_single_tf_2(img_to_test, scale=1, generate_data=False)\n",
    "print(time.strftime('%X'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pipeline_vision_single(model, img_to_test, scale=1, generate_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('process groups lines', 214, 17)\n"
     ]
    }
   ],
   "source": [
    "__lines = process_lines(img_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(__lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('connections', 23)\n",
      "(43232.95938551931, 4433.02901825174)\n",
      "(43232.95938551931, 38799.930367267574)\n",
      "small dif\n",
      "(4433.02901825174, 43232.95938551931)\n",
      "(38799.930367267574, 43232.95938551931)\n",
      "small dif\n",
      "(38799.930367267574, 4433.02901825174)\n",
      "('clear rectangles', 5, 3)\n",
      "('available_lines', 5, 3)\n",
      "('line parents', 4)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "__g_rectangles, __g_lines = geometry(__lines, [], img_to_test)\n",
    "print(len(__g_rectangles), len(__g_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
